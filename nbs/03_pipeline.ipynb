{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "\n",
    "> Complete pipeline for oligo codon counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Optional, Callable, Union, Tuple, Set\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from OligoSeeker.core import OligoCounter, OligoLoader\n",
    "from OligoSeeker.fastq import FastqHandler, OligoCodonProcessor\n",
    "from OligoSeeker.output import ResultsFormatter, ResultsSaver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class PipelineConfig:\n",
    "    \"\"\"Configuration settings for oligo codon counting pipeline.\"\"\"\n",
    "    # Required parameters\n",
    "    #fastq_path: str                  # Path to directory containing FASTQ files\n",
    "    fastq_1: str = \"../test_files/test_1.fq.gz\"   \n",
    "    fastq_2: str = \"../test_files/test_2.fq.gz\"   \n",
    "    \n",
    "    # Oligo configuration (one of these must be provided)\n",
    "    oligos_file: Optional[str] = None       # Path to file with oligo sequences\n",
    "    oligos_string: Optional[str] = None     # Comma-separated string of oligos\n",
    "    oligos_list: Optional[List[str]] = None # List of oligo sequences\n",
    "    \n",
    "    # Output configuration\n",
    "    output_path: str = \"../test_files/test_outs\"    # Path to save results\n",
    "    output_prefix: str = \"\"           # Prefix for output files\n",
    "    offset_oligo: int = 1             # Value to add to oligo index in output\n",
    "    \n",
    "    # Optional configuration\n",
    "    log_file: Optional[str] = None    # Path to log file (if None, logs to console)\n",
    "    log_level: int = logging.INFO     # Logging level\n",
    "    \n",
    "    def validate(self) -> None:\n",
    "        \"\"\"Validate configuration settings.\n",
    "        \n",
    "        Raises:\n",
    "            ValueError: If any settings are invalid\n",
    "        \"\"\"\n",
    "        # Check fastq_path exists\n",
    "        if not os.path.exists(self.fastq_1):\n",
    "            raise ValueError(f\"FASTQ path does not exist: {self.fastq_1}\")\n",
    "        if not os.path.exists(self.fastq_2):\n",
    "            raise ValueError(f\"FASTQ path does not exist: {self.fastq_1}\")\n",
    "            \n",
    "        \n",
    "        # Check that at least one oligo source is provided\n",
    "        oligo_sources = [self.oligos_file, self.oligos_string, self.oligos_list]\n",
    "        if not any(oligo_sources):\n",
    "            raise ValueError(\"No oligo source provided. Must specify one of: oligos_file, oligos_string, or oligos_list\")\n",
    "        \n",
    "        # Check oligos file exists if provided\n",
    "        if self.oligos_file and not os.path.exists(self.oligos_file):\n",
    "            raise ValueError(f\"Oligos file does not exist: {self.oligos_file}\")\n",
    "            \n",
    "    def get_output_filename(self, extension: str = \"csv\") -> str:\n",
    "        \"\"\"Generate output filename based on configuration.\n",
    "        \n",
    "        Args:\n",
    "            extension: File extension (default: 'csv')\n",
    "            \n",
    "        Returns:\n",
    "            Output filename\n",
    "        \"\"\"\n",
    "        if self.output_prefix:\n",
    "            filename = f\"{self.output_prefix}_counts\"\n",
    "        else:\n",
    "            filename = f\"counts\"\n",
    "        return f\"{filename}.{extension}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Progress Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "#not used\n",
    "class ProgressReporter:\n",
    "    \"\"\"Reports progress during long-running operations.\"\"\"\n",
    "    \n",
    "    def __init__(self, logger: Optional[logging.Logger] = None):\n",
    "        \"\"\"Initialize the progress reporter.\n",
    "        \n",
    "        Args:\n",
    "            logger: Logger instance to use for reporting\n",
    "        \"\"\"\n",
    "        self.logger = logger or logging.getLogger(__name__)\n",
    "        self.last_progress = 0\n",
    "        self.last_time = time.time()\n",
    "    \n",
    "    def report(self, current: int, total: int, min_interval: float = 2.0, min_change: float = 1.0) -> None:\n",
    "        \"\"\"Report progress if enough time has passed or enough progress has been made.\n",
    "        \n",
    "        Args:\n",
    "            current: Current progress value\n",
    "            total: Total expected value\n",
    "            min_interval: Minimum time interval between reports in seconds (default: 2.0)\n",
    "            min_change: Minimum percentage change to trigger a new report (default: 1.0)\n",
    "        \"\"\"\n",
    "        if total <= 0:\n",
    "            return\n",
    "            \n",
    "        now = time.time()\n",
    "        current_progress = (current / total) * 100\n",
    "        \n",
    "        # Check if we should report progress\n",
    "        time_passed = now - self.last_time >= min_interval\n",
    "        progress_made = abs(current_progress - self.last_progress) >= min_change\n",
    "        \n",
    "        if time_passed or progress_made or current >= total:\n",
    "            self.logger.info(f\"Progress: {current:,}/{total:,} reads processed ({current_progress:.1f}%)\")\n",
    "            self.last_progress = current_progress\n",
    "            self.last_time = now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oligo Codon Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class OligoCodonPipeline:\n",
    "    \"\"\"Complete pipeline for oligo codon counting.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: PipelineConfig):\n",
    "        \"\"\"Initialize the pipeline with configuration.\n",
    "        \n",
    "        Args:\n",
    "            config: Pipeline configuration\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "        self.logger = self._setup_logging()\n",
    "        self.oligos: List[str] = []\n",
    "        self.reporter = ProgressReporter(self.logger)\n",
    "    \n",
    "    def _setup_logging(self) -> logging.Logger:\n",
    "        \"\"\"Set up logging based on configuration.\n",
    "        \n",
    "        Returns:\n",
    "            Configured logger instance\n",
    "        \"\"\"\n",
    "        logger = logging.getLogger(\"OligoCodonPipeline\")\n",
    "        logger.setLevel(self.config.log_level)\n",
    "        \n",
    "        # Clear existing handlers\n",
    "        logger.handlers = []\n",
    "        \n",
    "        # Create formatter\n",
    "        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "        \n",
    "        # Always add console handler\n",
    "        console_handler = logging.StreamHandler()\n",
    "        console_handler.setFormatter(formatter)\n",
    "        logger.addHandler(console_handler)\n",
    "        \n",
    "        # Add file handler if specified\n",
    "        if self.config.log_file:\n",
    "            log_dir = os.path.dirname(self.config.log_file)\n",
    "            if log_dir and not os.path.exists(log_dir):\n",
    "                os.makedirs(log_dir)\n",
    "                \n",
    "            file_handler = logging.FileHandler(self.config.log_file)\n",
    "            file_handler.setFormatter(formatter)\n",
    "            logger.addHandler(file_handler)\n",
    "            \n",
    "        return logger\n",
    "    \n",
    "    def load_oligos(self) -> List[str]:\n",
    "        \"\"\"Load oligo sequences from the specified source.\n",
    "        \n",
    "        Returns:\n",
    "            List of oligo sequences\n",
    "            \n",
    "        Raises:\n",
    "            ValueError: If oligos cannot be loaded or are invalid\n",
    "        \"\"\"\n",
    "        self.logger.info(\"Loading oligo sequences...\")\n",
    "        \n",
    "        if self.config.oligos_file:\n",
    "            self.logger.info(f\"Loading oligos from file: {self.config.oligos_file}\")\n",
    "            oligos = OligoLoader.from_file(self.config.oligos_file)\n",
    "        elif self.config.oligos_string:\n",
    "            self.logger.info(\"Loading oligos from provided string\")\n",
    "            oligos = OligoLoader.from_string(self.config.oligos_string)\n",
    "        elif self.config.oligos_list:\n",
    "            self.logger.info(\"Using provided oligo list\")\n",
    "            oligos = OligoLoader.validate_oligos(self.config.oligos_list)\n",
    "        else:\n",
    "            raise ValueError(\"No oligo source specified\")\n",
    "            \n",
    "        self.logger.info(f\"Loaded {len(oligos)} oligo sequences\")\n",
    "        return oligos\n",
    "    \n",
    "    def find_fastq_files(self) -> Tuple[str, str]:\n",
    "        \"\"\"Find FASTQ files to process.\n",
    "        \n",
    "        Returns:\n",
    "            Tuple of (read1_path, read2_path)\n",
    "        \"\"\"\n",
    "        #self.logger.info(f\"Finding FASTQ files in: {self.config.fastq_path}\")\n",
    "        #r1_path, r2_path = FastqHandler.find_fastq_pairs(self.config.fastq_path)\n",
    "        #self.logger.info(f\"Found FASTQ pair: {os.path.basename(r1_path)} and {os.path.basename(r2_path)}\")\n",
    "        return (self.config.fastq_1, self.config.fastq_2)\n",
    "    \n",
    "    def progress_callback(self, current: int, total: int) -> None:\n",
    "        \"\"\"Callback for reporting progress.\n",
    "        \n",
    "        Args:\n",
    "            current: Current progress value\n",
    "            total: Total expected value\n",
    "        \"\"\"\n",
    "        self.reporter.report(current, total)\n",
    "    \n",
    "    def run(self) -> Dict:\n",
    "        \"\"\"Execute the complete pipeline.\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary with pipeline results and statistics\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        self.logger.info(\"Starting OligoCodonPipeline\")\n",
    "        \n",
    "        # Validate configuration\n",
    "        self.config.validate()\n",
    "        \n",
    "        # Load oligos\n",
    "        self.oligos = self.load_oligos()\n",
    "        \n",
    "        # Find FASTQ files\n",
    "        r1_path, r2_path = self.find_fastq_files()\n",
    "        \n",
    "        # Process FASTQ files\n",
    "        self.logger.info(\"Processing FASTQ files...\")\n",
    "        processor = OligoCodonProcessor(self.oligos)\n",
    "        results = processor.process_fastq_pair(r1_path, r2_path, self.progress_callback)\n",
    "        \n",
    "        # Format results\n",
    "        self.logger.info(\"Formatting results...\")\n",
    "        result_df = ResultsFormatter.to_dataframe(results, self.oligos, self.config.offset_oligo)\n",
    "        \n",
    "        # Save results\n",
    "        output_file = self.config.get_output_filename()\n",
    "        self.logger.info(f\"Saving results to: {os.path.join(self.config.output_path, output_file)}\")\n",
    "        saved_path = ResultsSaver.save_csv(result_df, self.config.output_path, output_file)\n",
    "        \n",
    "        # Generate summary\n",
    "        summary = ResultsFormatter.summarize_results(result_df)\n",
    "        \n",
    "        \n",
    "        # Calculate elapsed time\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        self.logger.info(f\"Pipeline completed in {elapsed_time:.2f} seconds\")\n",
    "        \n",
    "        # Return results\n",
    "        return {\n",
    "            \"csv_path\": saved_path,\n",
    "            #\"excel_path\": excel_path,\n",
    "            #\"json_path\": json_path,\n",
    "            \"oligos_processed\": len(self.oligos),\n",
    "            \"elapsed_time\": elapsed_time,\n",
    "            \"summary\": summary\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
